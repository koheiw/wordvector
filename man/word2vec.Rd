% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/word2vec.R
\name{word2vec}
\alias{word2vec}
\title{Word2vec model}
\usage{
word2vec(
  x,
  dim = 50,
  type = c("cbow", "skip-gram"),
  min_count = 5L,
  window = ifelse(type == "cbow", 5L, 10L),
  iter = 10L,
  alpha = 0.05,
  use_ns = TRUE,
  ns_size = 5L,
  sample = 0.001,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{x}{a [quanteda::tokens] object.}

\item{dim}{size of the word vectors.}

\item{type}{the architecture of the model; either "cbow" (continuous back of words) or "skip-gram".}

\item{min_count}{the minimum frequency of the words. Words less frequent than this in the `tokens` object are removed before training.}

\item{window}{the size of the word window. Words within this window are considered to be the context of a target word.}

\item{iter}{number of iterations in training the model.}

\item{alpha}{the initial learning rate.}

\item{use_ns}{if `TRUE`, negative sampling is used. Otherwise, hierarchical softmax is used.}

\item{ns_size}{the size of negative samples. Only used when `use_ns = TRUE`.}

\item{sample}{the rate of sampling of words based on theri frequency. Sampling is disabled when `sample = 1.0`}

\item{...}{additional arguments.}
}
\value{

}
\description{
Train a Word2vec model (Mikolov et al., 2023) <https://arxiv.org/pdf/1310.4546.pdf> on a [quanteda::tokens] object.
}
\references{
\url{https://github.com/maxoodf/word2vec}, \url{https://arxiv.org/pdf/1310.4546.pdf}
}
